#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ä¼˜åŒ–å›æµ‹è„šæœ¬ - ä½¿ç”¨å›æµ‹ä¸“ç”¨é…ç½®
- æ”¾å®½ç­›é€‰æ¡ä»¶ï¼Œç¡®ä¿è¶³å¤Ÿæ ·æœ¬
- æ·»åŠ æ•°æ®ç¼“å­˜
- è‡ªåŠ¨ç”ŸæˆæŠ¥å‘Š
"""

import sys
import os

# è®¾ç½®æ§åˆ¶å°ç¼–ç ä¸ºUTF-8
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
import akshare as ak
import pandas as pd
from datetime import datetime, timedelta
import logging
import json
import time
import pickle

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from src.data.data_fetcher import StockDataFetcher
from src.analysis.stock_filter import StockFilter
from config.backtest_config import BACKTEST_FILTER_CONFIG, BACKTEST_SAMPLE_CONFIG

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class OptimizedBacktest:
    """ä¼˜åŒ–å›æµ‹ç³»ç»Ÿ - ä½¿ç”¨å®½æ¾é…ç½®"""

    def __init__(self):
        self.data_fetcher = StockDataFetcher()
        # ä½¿ç”¨å›æµ‹ä¸“ç”¨é…ç½®
        self.stock_filter = StockFilter(config=BACKTEST_FILTER_CONFIG)
        self.cache_dir = './cache'
        os.makedirs(self.cache_dir, exist_ok=True)
        self.stock_name_cache = {}  # è‚¡ç¥¨åç§°ç¼“å­˜

    def get_cache_file(self, cache_key):
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        return os.path.join(self.cache_dir, f"{cache_key}.pkl")

    def load_from_cache(self, cache_key):
        """ä»ç¼“å­˜åŠ è½½æ•°æ®"""
        cache_file = self.get_cache_file(cache_key)
        if os.path.exists(cache_file):
            try:
                # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
                expire_days = BACKTEST_SAMPLE_CONFIG.get('cache_expire_days', 7)
                if time.time() - os.path.getmtime(cache_file) < (expire_days * 86400):
                    with open(cache_file, 'rb') as f:
                        return pickle.load(f)
            except:
                pass
        return None

    def save_to_cache(self, cache_key, data):
        """ä¿å­˜æ•°æ®åˆ°ç¼“å­˜"""
        cache_file = self.get_cache_file(cache_key)
        try:
            with open(cache_file, 'wb') as f:
                pickle.dump(data, f)
        except Exception as e:
            logger.warning(f"ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")

    def get_stock_name(self, stock_code: str):
        """è·å–è‚¡ç¥¨åç§°ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        if stock_code in self.stock_name_cache:
            return self.stock_name_cache[stock_code]

        try:
            # ä½¿ç”¨akshareè·å–è‚¡ç¥¨ä¿¡æ¯
            info = ak.stock_individual_info_em(symbol=stock_code)
            if not info.empty:
                name = info[info['item'] == 'è‚¡ç¥¨ç®€ç§°']['value'].values
                if len(name) > 0:
                    stock_name = str(name[0])
                    self.stock_name_cache[stock_code] = stock_name
                    return stock_name
        except:
            pass

        # å¦‚æœè·å–å¤±è´¥ï¼Œä½¿ç”¨ä»£ç ä½œä¸ºåç§°
        return f'è‚¡ç¥¨{stock_code}'

    def get_csi300_stocks(self):
        """è·å–æ²ªæ·±300æˆåˆ†è‚¡åˆ—è¡¨ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        cache_key = "csi300_stocks_with_names"
        cached_data = self.load_from_cache(cache_key)

        if cached_data:
            logger.info(f"ä»ç¼“å­˜åŠ è½½æ²ªæ·±300æˆåˆ†è‚¡: {len(cached_data.get('stocks', []))} åª")
            # æ¢å¤åç§°ç¼“å­˜
            if isinstance(cached_data, dict):
                self.stock_name_cache = cached_data.get('name_cache', {})
                return cached_data.get('stocks', [])
            return cached_data

        # å°è¯•å¤šç§æ–¹æ³•è·å–æˆåˆ†è‚¡
        stocks = []

        # æ–¹æ³•1: ä½¿ç”¨akshareè·å–ï¼ˆå¯èƒ½å¤±è´¥ï¼‰
        try:
            logger.info("æ­£åœ¨è·å–æ²ªæ·±300æˆåˆ†è‚¡åˆ—è¡¨ï¼ˆæ–¹æ³•1ï¼šakshareï¼‰...")
            csi300 = ak.index_stock_cons(symbol="000300")
            stocks = csi300['å“ç§ä»£ç '].tolist()

            # åŒæ—¶è·å–è‚¡ç¥¨åç§°
            logger.info("æ­£åœ¨è·å–è‚¡ç¥¨åç§°...")
            for i, code in enumerate(stocks):
                name = csi300[csi300['å“ç§ä»£ç '] == code]['å“ç§åç§°'].values
                if len(name) > 0:
                    self.stock_name_cache[code] = str(name[0])
                if (i + 1) % 50 == 0:
                    logger.info(f"  åç§°è·å–è¿›åº¦: {i+1}/{len(stocks)}")

            logger.info(f"âœ… æˆåŠŸè·å– {len(stocks)} åªæ²ªæ·±300æˆåˆ†è‚¡åŠåç§°")
        except Exception as e:
            logger.warning(f"âš ï¸ æ–¹æ³•1å¤±è´¥: {e}")

            # æ–¹æ³•2: ä½¿ç”¨å¤‡ç”¨æ¥å£
            try:
                logger.info("æ­£åœ¨å°è¯•æ–¹æ³•2ï¼šå¤‡ç”¨æ¥å£...")
                time.sleep(2)
                csi300 = ak.index_stock_cons_csindex(symbol="000300")
                stocks = csi300['æˆåˆ†åˆ¸ä»£ç '].tolist()
                logger.info(f"âœ… æ–¹æ³•2æˆåŠŸè·å– {len(stocks)} åªè‚¡ç¥¨")
            except Exception as e2:
                logger.error(f"âŒ æ–¹æ³•2ä¹Ÿå¤±è´¥: {e2}")

        if not stocks:
            logger.error("âŒ æ— æ³•è·å–æ²ªæ·±300æˆåˆ†è‚¡åˆ—è¡¨ï¼Œæ‰€æœ‰æ–¹æ³•å‡å¤±è´¥")
            return []

        # ä¿å­˜è‚¡ç¥¨åˆ—è¡¨å’Œåç§°ç¼“å­˜
        cache_data = {
            'stocks': stocks,
            'name_cache': self.stock_name_cache
        }
        self.save_to_cache(cache_key, cache_data)
        return stocks

    def get_stock_data_for_date(self, stock_code: str, date: str, pe_ratio: float = None, purpose: str = "buy"):
        """è·å–æŒ‡å®šæ—¥æœŸçš„è‚¡ç¥¨æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        # ä¸ºä¹°å…¥å’Œå–å‡ºä½¿ç”¨ä¸åŒçš„ç¼“å­˜é”®ï¼Œé¿å…å†²çª
        cache_key = f"stock_{stock_code}_{date}_{purpose}"
        cached_data = self.load_from_cache(cache_key)

        if cached_data:
            # å¦‚æœæä¾›äº†æ–°çš„PEå€¼ï¼Œæ›´æ–°ç¼“å­˜æ•°æ®
            if pe_ratio is not None and pe_ratio > 0:
                cached_data['pe_ratio'] = pe_ratio
            return cached_data

        try:
            end_date = (datetime.strptime(date, '%Y-%m-%d') + timedelta(days=5)).strftime('%Y%m%d')
            start_date = (datetime.strptime(date, '%Y-%m-%d') - timedelta(days=35)).strftime('%Y%m%d')

            df = ak.stock_zh_a_hist(symbol=stock_code, period="daily",
                                   start_date=start_date, end_date=end_date, adjust="qfq")

            if df.empty:
                return None

            df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
            target_date = pd.to_datetime(date)

            df_on_date = df[df['æ—¥æœŸ'] <= target_date]
            if df_on_date.empty:
                return None

            row = df_on_date.iloc[-1]

            # è·å–çœŸå®è‚¡ç¥¨åç§°
            stock_name = self.get_stock_name(stock_code)

            # è·å–PEæ•°æ®ï¼ˆä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„å€¼ï¼‰
            final_pe_ratio = 20.0  # é»˜è®¤å€¼
            if pe_ratio is not None and pe_ratio > 0:
                final_pe_ratio = pe_ratio
            elif 'å¸‚ç›ˆç‡' in row:
                try:
                    pe_value = row['å¸‚ç›ˆç‡']
                    if pe_value and pe_value > 0:
                        final_pe_ratio = float(pe_value)
                except:
                    pass

            # è®¡ç®—20æ—¥åŠ¨é‡
            momentum_20d = 0
            if len(df_on_date) >= 20:
                price_20d_ago = df_on_date.iloc[-20]['æ”¶ç›˜']
                current_price = row['æ”¶ç›˜']
                momentum_20d = (current_price / price_20d_ago - 1) * 100
            elif len(df_on_date) >= 2:
                # å¦‚æœæ•°æ®ä¸è¶³20å¤©ï¼Œä½¿ç”¨å¯ç”¨çš„å¤©æ•°
                price_start = df_on_date.iloc[0]['æ”¶ç›˜']
                current_price = row['æ”¶ç›˜']
                momentum_20d = (current_price / price_start - 1) * 100

            data = {
                'code': stock_code,
                'name': stock_name,
                'price': float(row['æ”¶ç›˜']),
                'change_pct': float(row['æ¶¨è·Œå¹…']),
                'volume': int(row['æˆäº¤é‡']),
                'turnover': float(row['æˆäº¤é¢']),
                'pe_ratio': final_pe_ratio,
                'momentum_20d': momentum_20d,
                'strength_score': 0
            }

            self.save_to_cache(cache_key, data)
            return data

        except Exception as e:
            logger.debug(f"è·å– {stock_code} æ•°æ®å¤±è´¥: {e}")
            return None

    def get_next_trading_day(self, date: str, days: int = 1):
        """è·å–ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥"""
        try:
            current = datetime.strptime(date, '%Y-%m-%d')
            for i in range(1, 15):
                next_date = current + timedelta(days=i*days)
                if next_date.weekday() < 5:
                    return next_date.strftime('%Y-%m-%d')
            return (current + timedelta(days=days)).strftime('%Y-%m-%d')
        except:
            return date

    def fetch_pe_ratios_batch(self, stock_codes: list) -> dict:
        """æ‰¹é‡è·å–è‚¡ç¥¨PEæ•°æ®(ä½¿ç”¨è…¾è®¯API)"""
        pe_dict = {}
        logger.info("ğŸ“Š æ­£åœ¨è·å–PEæ•°æ®(ä½¿ç”¨è…¾è®¯è´¢ç»API)...")

        success_count = 0
        for i, code in enumerate(stock_codes):
            try:
                stock_data = self.data_fetcher.get_stock_realtime_data(code)
                if stock_data and stock_data.get('pe_ratio'):
                    pe_dict[code] = stock_data['pe_ratio']
                    success_count += 1

                # æ¯50ä¸ªè‚¡ç¥¨æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                if (i + 1) % 50 == 0:
                    logger.info(f"   è¿›åº¦: {i+1}/{len(stock_codes)}")
            except:
                pass

        logger.info(f"âœ… æˆåŠŸè·å– {success_count}/{len(stock_codes)} åªè‚¡ç¥¨çš„PEæ•°æ®")
        return pe_dict

    def backtest_single_day(self, analysis_date: str, hold_days: int = 1):
        """å›æµ‹å•æ—¥ç­–ç•¥"""
        logger.info(f"\n{'='*70}")
        logger.info(f"ğŸ“… å›æµ‹æ—¥æœŸ: {analysis_date} | æŒæœ‰{hold_days}å¤©")
        logger.info(f"{'='*70}")

        # è·å–æ²ªæ·±300æˆåˆ†è‚¡
        stock_list = self.get_csi300_stocks()
        if not stock_list:
            logger.error("æ— æ³•è·å–æ²ªæ·±300æˆåˆ†è‚¡åˆ—è¡¨")
            return None

        # é‡‡æ ·ï¼ˆå¦‚æœsample_size >= 300åˆ™ä½¿ç”¨å…¨éƒ¨ï¼‰
        sample_size = BACKTEST_SAMPLE_CONFIG['sample_size']
        if sample_size >= len(stock_list):
            logger.info(f"ğŸ“Š ä½¿ç”¨å…¨éƒ¨æ²ªæ·±300æˆåˆ†è‚¡: {len(stock_list)}åª")
            sampled_stocks = stock_list
        else:
            logger.info(f"ğŸ“Š é‡‡æ ·é…ç½®: {sample_size}åªè‚¡ç¥¨")
            import random
            random.seed(BACKTEST_SAMPLE_CONFIG['random_seed'])
            sampled_stocks = random.sample(stock_list, min(sample_size, len(stock_list)))

        # æ‰¹é‡è·å–PEæ•°æ®
        pe_ratios = self.fetch_pe_ratios_batch(sampled_stocks)

        stock_data = []
        for i, code in enumerate(sampled_stocks):
            if i % 20 == 0:
                logger.info(f"â³ æ•°æ®è·å–è¿›åº¦: {i+1}/{len(sampled_stocks)}")

            # è·å–ä¹°å…¥æ•°æ®æ—¶æ ‡è®°purposeä¸º"buy"
            data = self.get_stock_data_for_date(code, analysis_date, pe_ratios.get(code), "buy")
            if data:
                stock_data.append(data)

            if i % 20 == 19:
                time.sleep(0.3)

        logger.info(f"âœ… æˆåŠŸè·å– {len(stock_data)}/{sample_size} åªè‚¡ç¥¨æ•°æ®")

        if len(stock_data) < 10:
            logger.error("âŒ è·å–çš„è‚¡ç¥¨æ•°æ®å¤ªå°‘")
            return None

        # ä½¿ç”¨å›æµ‹é…ç½®ç­›é€‰
        logger.info(f"\nğŸ” ç­›é€‰é…ç½®:")
        logger.info(f"   â€¢ PEä¸Šé™: {BACKTEST_FILTER_CONFIG['max_pe_ratio']}")
        logger.info(f"   â€¢ æˆäº¤é¢: {BACKTEST_FILTER_CONFIG['min_turnover']/10000:.0f}ä¸‡å…ƒ")
        logger.info(f"   â€¢ å¼ºåŠ¿åˆ†æ•°: â‰¥{BACKTEST_FILTER_CONFIG['min_strength_score']}")
        logger.info(f"   â€¢ æ¨èæ•°é‡: {BACKTEST_FILTER_CONFIG['max_stocks']}åª")

        # è°ƒç”¨ç­›é€‰å™¨é€‰æ‹©è‚¡ç¥¨
        selected_stocks = self.stock_filter.select_top_stocks(stock_data)

        if not selected_stocks:
            logger.warning("âš ï¸  æœªç­›é€‰å‡ºä»»ä½•è‚¡ç¥¨")
            return {
                'analysis_date': analysis_date,
                'selected_count': 0,
                'performance': [],
                'config_used': 'backtest_relaxed'
            }

        # åœ¨è¾“å‡ºç­›é€‰ç»“æœå‰å¢åŠ å»é‡æ£€æŸ¥
        unique_stocks = []
        seen_codes = set()
        
        for stock in selected_stocks:
            if stock['code'] not in seen_codes:
                unique_stocks.append(stock)
                seen_codes.add(stock['code'])
            else:
                logger.warning(f"å‘ç°é‡å¤è‚¡ç¥¨ä»£ç : {stock['code']} ({stock['name']})ï¼Œå·²è·³è¿‡é‡å¤é¡¹")
        
        selected_stocks = unique_stocks
        
        logger.info(f"\nğŸ† ç­›é€‰ç»“æœ ({len(selected_stocks)}åª):")
        for stock in selected_stocks:
            logger.info(f"   #{stock['rank']} {stock['name']} ({stock['code']}): "
                       f"Â¥{stock['price']:.2f}, PE={stock.get('pe_ratio', 0):.1f}, "
                       f"åˆ†æ•°={stock.get('strength_score', 0):.0f}")

        # è®¡ç®—æ”¶ç›Š
        sell_date = self.get_next_trading_day(analysis_date, hold_days)
        logger.info(f"\nğŸ’° æ”¶ç›Šè®¡ç®— (å–å‡ºæ—¥æœŸ: {sell_date}):")

        performance = []
        for stock in selected_stocks:
            # è·å–å–å‡ºæ•°æ®æ—¶æ ‡è®°purposeä¸º"sell"
            sell_data = self.get_stock_data_for_date(stock['code'], sell_date, purpose="sell")
            if sell_data:
                buy_price = stock['price']
                sell_price = sell_data['price']
                return_pct = (sell_price / buy_price - 1) * 100

                performance.append({
                    'code': stock['code'],
                    'name': stock['name'],
                    'buy_price': buy_price,
                    'sell_price': sell_price,
                    'return_pct': return_pct,
                    'pe_ratio': stock.get('pe_ratio', 0),
                    'strength_score': stock.get('strength_score', 0)
                })

                emoji = "ğŸ“ˆ" if return_pct > 0 else "ğŸ“‰" if return_pct < 0 else "â–"
                logger.info(f"   {emoji} {stock['name']}: Â¥{buy_price:.2f} â†’ Â¥{sell_price:.2f} ({return_pct:+.2f}%)")

        # ç»Ÿè®¡
        if performance:
            returns = [p['return_pct'] for p in performance]
            avg_return = sum(returns) / len(returns)
            max_return = max(returns)
            min_return = min(returns)
            win_count = len([r for r in returns if r > 0])
            win_rate = win_count / len(returns) * 100

            logger.info(f"\nğŸ“Š ç­–ç•¥è¡¨ç°:")
            logger.info(f"   â€¢ å¹³å‡æ”¶ç›Š: {avg_return:+.2f}%")
            logger.info(f"   â€¢ æ”¶ç›ŠåŒºé—´: {min_return:+.2f}% ~ {max_return:+.2f}%")
            logger.info(f"   â€¢ èƒœç‡: {win_rate:.1f}% ({win_count}/{len(returns)})")

        return {
            'analysis_date': analysis_date,
            'sell_date': sell_date,
            'hold_days': hold_days,
            'selected_count': len(selected_stocks),
            'sample_size': len(stock_data),
            'performance': performance,
            'config_used': 'backtest_relaxed',
            'filter_config': BACKTEST_FILTER_CONFIG,
            'summary': {
                'avg_return': avg_return if performance else 0,
                'max_return': max_return if performance else 0,
                'min_return': min_return if performance else 0,
                'win_rate': win_rate if performance else 0,
                'win_count': win_count if performance else 0,
                'total_count': len(performance)
            }
        }

    def backtest_multi_days(self, start_date: str, end_date: str, hold_days: int = 1):
        """å¤šæ—¥å›æµ‹"""
        logger.info(f"\n{'='*70}")
        logger.info(f"ğŸ“… å¤šæ—¥å›æµ‹: {start_date} ~ {end_date}")
        logger.info(f"{'='*70}")

        # ç”Ÿæˆäº¤æ˜“æ—¥
        trading_days = []
        current = datetime.strptime(start_date, '%Y-%m-%d')
        end = datetime.strptime(end_date, '%Y-%m-%d')

        while current <= end:
            if current.weekday() < 5:
                trading_days.append(current.strftime('%Y-%m-%d'))
            current += timedelta(days=1)

        logger.info(f"å…± {len(trading_days)} ä¸ªäº¤æ˜“æ—¥")

        all_results = []
        for i, date in enumerate(trading_days):
            logger.info(f"\n{'='*70}")
            logger.info(f"è¿›åº¦: {i+1}/{len(trading_days)}")

            result = self.backtest_single_day(date, hold_days)
            if result and result['selected_count'] > 0:
                all_results.append(result)

            time.sleep(1)

        # æ±‡æ€»
        if all_results:
            all_returns = []
            for r in all_results:
                all_returns.extend([p['return_pct'] for p in r['performance']])

            logger.info(f"\n{'='*70}")
            logger.info(f"ğŸ“Š å›æµ‹æ€»ç»“:")
            logger.info(f"{'='*70}")
            logger.info(f"   â€¢ æœ‰æ•ˆäº¤æ˜“æ—¥: {len(all_results)}")
            logger.info(f"   â€¢ æ€»äº¤æ˜“æ¬¡æ•°: {len(all_returns)}")
            if all_returns:
                logger.info(f"   â€¢ æ•´ä½“å¹³å‡æ”¶ç›Š: {sum(all_returns)/len(all_returns):+.2f}%")
                logger.info(f"   â€¢ æœ€ä½³å•ç¬”: {max(all_returns):+.2f}%")
                logger.info(f"   â€¢ æœ€å·®å•ç¬”: {min(all_returns):+.2f}%")
                win_count = len([r for r in all_returns if r > 0])
                logger.info(f"   â€¢ æ•´ä½“èƒœç‡: {win_count/len(all_returns)*100:.1f}%")

        return all_results


def main():
    """ä¸»å‡½æ•°"""
    print("="*70)
    print("ğŸ“Š æ²ªæ·±300ç­–ç•¥å›æµ‹ç³»ç»Ÿ (ä¼˜åŒ–é…ç½®ç‰ˆ)")
    print("="*70)
    print("âœ¨ é…ç½®ç‰¹æ€§:")
    print(f"   â€¢ PEä¸Šé™: {BACKTEST_FILTER_CONFIG['max_pe_ratio']} (å®ç›˜30)")
    print(f"   â€¢ æˆäº¤é¢: {BACKTEST_FILTER_CONFIG['min_turnover']/10000:.0f}ä¸‡å…ƒ (å®ç›˜5000ä¸‡)")
    print(f"   â€¢ å¼ºåŠ¿åˆ†æ•°: â‰¥{BACKTEST_FILTER_CONFIG['min_strength_score']} (å®ç›˜50)")
    print(f"   â€¢ æ¨èæ•°é‡: {BACKTEST_FILTER_CONFIG['max_stocks']}åª (å®ç›˜3åª)")
    if BACKTEST_SAMPLE_CONFIG['sample_size'] >= 300:
        print(f"   â€¢ è‚¡ç¥¨æ± : å…¨éƒ¨æ²ªæ·±300æˆåˆ†è‚¡")
    else:
        print(f"   â€¢ é‡‡æ ·æ•°é‡: {BACKTEST_SAMPLE_CONFIG['sample_size']}åª")
    print("="*70)

    backtest = OptimizedBacktest()

    print("\nè¯·é€‰æ‹©å›æµ‹æ¨¡å¼:")
    print("1. å•æ—¥å›æµ‹")
    print("2. å¤šæ—¥å›æµ‹ (å»ºè®®â‰¤5å¤©)")

    choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (1/2): ").strip()

    if choice == '1':
        date = input("è¯·è¾“å…¥å›æµ‹æ—¥æœŸ (ä¾‹: 2025-09-25): ").strip() or '2025-09-25'
        hold_days = int(input("è¯·è¾“å…¥æŒæœ‰å¤©æ•° (é»˜è®¤1å¤©): ").strip() or '1')

        result = backtest.backtest_single_day(date, hold_days)

        if result:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs('./logs/backtest', exist_ok=True)
            filename = f"./logs/backtest/backtest_opt_{date}_{hold_days}days.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            logger.info(f"\nâœ… å›æµ‹ç»“æœå·²ä¿å­˜: {filename}")

    elif choice == '2':
        start_date = input("è¯·è¾“å…¥å¼€å§‹æ—¥æœŸ (ä¾‹: 2025-09-23): ").strip() or '2025-09-23'
        end_date = input("è¯·è¾“å…¥ç»“æŸæ—¥æœŸ (ä¾‹: 2025-09-27): ").strip() or '2025-09-27'
        hold_days = int(input("è¯·è¾“å…¥æŒæœ‰å¤©æ•° (é»˜è®¤1å¤©): ").strip() or '1')

        results = backtest.backtest_multi_days(start_date, end_date, hold_days)

        if results:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs('./logs/backtest', exist_ok=True)
            filename = f"./logs/backtest/backtest_opt_{start_date}_to_{end_date}.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            logger.info(f"\nâœ… å›æµ‹ç»“æœå·²ä¿å­˜: {filename}")

    else:
        print("æ— æ•ˆçš„é€‰é¡¹")


if __name__ == "__main__":
    main()